{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'god': 3,\n",
       " '.': 4,\n",
       " 'of': 5,\n",
       " 'light': 6,\n",
       " 'was': 7,\n",
       " ',': 8,\n",
       " ':': 9,\n",
       " 'called': 10,\n",
       " 'darkness': 11,\n",
       " 'king': 12,\n",
       " 'james': 13,\n",
       " 'bible': 14,\n",
       " 'first': 15,\n",
       " 'earth': 16,\n",
       " 'upon': 17,\n",
       " 'face': 18,\n",
       " 'there': 19,\n",
       " 'day': 20,\n",
       " 'old': 21,\n",
       " 'testament': 22,\n",
       " 'book': 23,\n",
       " 'moses': 24,\n",
       " 'genesis': 25,\n",
       " 'in': 26,\n",
       " 'beginning': 27,\n",
       " 'created': 28,\n",
       " 'heaven': 29,\n",
       " 'without': 30,\n",
       " 'form': 31,\n",
       " 'void': 32,\n",
       " ';': 33,\n",
       " 'deep': 34,\n",
       " 'spirit': 35,\n",
       " 'moved': 36,\n",
       " 'waters': 37,\n",
       " 'said': 38,\n",
       " 'let': 39,\n",
       " 'be': 40,\n",
       " 'saw': 41,\n",
       " 'that': 42,\n",
       " 'it': 43,\n",
       " 'good': 44,\n",
       " 'divided': 45,\n",
       " 'from': 46,\n",
       " 'he': 47,\n",
       " 'night': 48,\n",
       " 'evening': 49,\n",
       " 'morning': 50,\n",
       " 'were': 51}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "\n",
    "data = [['The', 'King', 'James', 'Bible'], \n",
    "        ['The', 'Old', 'Testament', 'of', 'the', 'King', 'James', 'Bible'], \n",
    "        ['The', 'First', 'Book', 'of', 'Moses', ':', 'Called', 'Genesis'], \n",
    "        ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth'], \n",
    "        ['And', 'the', 'earth', 'was', 'without', 'form', ',', 'and', 'void', ';', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep', '.'], \n",
    "        ['And', 'the', 'Spirit', 'of', 'God', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters', '.'], \n",
    "        ['And', 'God', 'said', ',', 'Let', 'there', 'be', 'light', ':', 'and', 'there', 'was', 'light', '.'], \n",
    "        ['And', 'God', 'saw', 'the', 'light', ',', 'that', 'it', 'was', 'good', ':', 'and', 'God', 'divided', 'the', 'light', 'from', 'the', 'darkness', '.'], \n",
    "        ['And', 'God', 'called', 'the', 'light', 'Day', ',', 'and', 'the', 'darkness', 'he', 'called', 'Night', '.'], \n",
    "        ['And', 'the', 'evening', 'and', 'the', 'morning', 'were', 'the', 'first', 'day', '.']]\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(data)\n",
    "\n",
    "word2id = t.word_index\n",
    "\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "\n",
    "vocab_size = len(word2id) + 1 \n",
    "embed_size = 100\n",
    "\n",
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 12, 13, 14],\n",
       " [1, 21, 22, 5, 1, 12, 13, 14],\n",
       " [1, 15, 23, 5, 24, 9, 10, 25],\n",
       " [26, 1, 27, 3, 28, 1, 29, 2, 1, 16],\n",
       " [2, 1, 16, 7, 30, 31, 8, 2, 32, 33, 2, 11, 7, 17, 1, 18, 5, 1, 34, 4],\n",
       " [2, 1, 35, 5, 3, 36, 17, 1, 18, 5, 1, 37, 4],\n",
       " [2, 3, 38, 8, 39, 19, 40, 6, 9, 2, 19, 7, 6, 4],\n",
       " [2, 3, 41, 1, 6, 8, 42, 43, 7, 44, 9, 2, 3, 45, 1, 6, 46, 1, 11, 4],\n",
       " [2, 3, 10, 1, 6, 20, 8, 2, 1, 11, 47, 10, 48, 4],\n",
       " [2, 1, 49, 2, 1, 50, 51, 1, 15, 20, 4]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wids = [[word2id[w.lower()] for w in doc] for doc in data]\n",
    "\n",
    "wids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate skip-grams\n",
    "skip_grams = [skipgrams(wid, vocabulary_size=vocab_size, window_size=3) for wid in wids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(the (1), bible (14))\n",
      "(the (1), , (8))\n",
      "(the (1), be (40))\n",
      "(bible (14), beginning (27))\n",
      "(king (12), there (19))\n",
      "(king (12), he (47))\n",
      "(king (12), upon (17))\n",
      "(king (12), the (1))\n",
      "(james (13), testament (22))\n",
      "(james (13), bible (14))\n"
     ]
    }
   ],
   "source": [
    "pairs = skip_grams[0][0]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d}))\".format(\n",
    "          id2word[pairs[i][0]], pairs[i][0], \n",
    "          id2word[pairs[i][1]], pairs[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
