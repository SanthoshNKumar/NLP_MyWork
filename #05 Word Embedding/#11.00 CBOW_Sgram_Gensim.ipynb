{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\\\MyWork\\\\MyLearning\\\\ML\\\\Files\\\\DataSet\\\\alice.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?' So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.  There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, `Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#  Reads ‘alice.txt’ file \n",
    "sample = open(\"C:\\\\MyWork\\\\MyLearning\\\\ML\\\\Files\\\\DataSet\\\\alice.txt\", \"r\") \n",
    "s = sample.read() \n",
    "\n",
    "# Replaces escape character with space \n",
    "f = s.replace(\"\\n\", \" \") \n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['alice',\n",
       "  'was',\n",
       "  'beginning',\n",
       "  'to',\n",
       "  'get',\n",
       "  'very',\n",
       "  'tired',\n",
       "  'of',\n",
       "  'sitting',\n",
       "  'by',\n",
       "  'her',\n",
       "  'sister',\n",
       "  'on',\n",
       "  'the',\n",
       "  'bank',\n",
       "  ',',\n",
       "  'and',\n",
       "  'of',\n",
       "  'having',\n",
       "  'nothing',\n",
       "  'to',\n",
       "  'do',\n",
       "  ':',\n",
       "  'once',\n",
       "  'or',\n",
       "  'twice',\n",
       "  'she',\n",
       "  'had',\n",
       "  'peeped',\n",
       "  'into',\n",
       "  'the',\n",
       "  'book',\n",
       "  'her',\n",
       "  'sister',\n",
       "  'was',\n",
       "  'reading',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  'had',\n",
       "  'no',\n",
       "  'pictures',\n",
       "  'or',\n",
       "  'conversations',\n",
       "  'in',\n",
       "  'it',\n",
       "  ',',\n",
       "  '`',\n",
       "  'and',\n",
       "  'what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'a',\n",
       "  'book',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'thought',\n",
       "  'alice',\n",
       "  '`',\n",
       "  'without',\n",
       "  'pictures',\n",
       "  'or',\n",
       "  'conversation',\n",
       "  '?',\n",
       "  \"'\"],\n",
       " ['so',\n",
       "  'she',\n",
       "  'was',\n",
       "  'considering',\n",
       "  'in',\n",
       "  'her',\n",
       "  'own',\n",
       "  'mind',\n",
       "  '(',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'she',\n",
       "  'could',\n",
       "  ',',\n",
       "  'for',\n",
       "  'the',\n",
       "  'hot',\n",
       "  'day',\n",
       "  'made',\n",
       "  'her',\n",
       "  'feel',\n",
       "  'very',\n",
       "  'sleepy',\n",
       "  'and',\n",
       "  'stupid',\n",
       "  ')',\n",
       "  ',',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'pleasure',\n",
       "  'of',\n",
       "  'making',\n",
       "  'a',\n",
       "  'daisy-chain',\n",
       "  'would',\n",
       "  'be',\n",
       "  'worth',\n",
       "  'the',\n",
       "  'trouble',\n",
       "  'of',\n",
       "  'getting',\n",
       "  'up',\n",
       "  'and',\n",
       "  'picking',\n",
       "  'the',\n",
       "  'daisies',\n",
       "  ',',\n",
       "  'when',\n",
       "  'suddenly',\n",
       "  'a',\n",
       "  'white',\n",
       "  'rabbit',\n",
       "  'with',\n",
       "  'pink',\n",
       "  'eyes',\n",
       "  'ran',\n",
       "  'close',\n",
       "  'by',\n",
       "  'her',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'was',\n",
       "  'nothing',\n",
       "  'so',\n",
       "  'very',\n",
       "  'remarkable',\n",
       "  'in',\n",
       "  'that',\n",
       "  ';',\n",
       "  'nor',\n",
       "  'did',\n",
       "  'alice',\n",
       "  'think',\n",
       "  'it',\n",
       "  'so',\n",
       "  'very',\n",
       "  'much',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'way',\n",
       "  'to',\n",
       "  'hear',\n",
       "  'the',\n",
       "  'rabbit',\n",
       "  'say',\n",
       "  'to',\n",
       "  'itself',\n",
       "  ',',\n",
       "  '`',\n",
       "  'oh',\n",
       "  'dear',\n",
       "  '!'],\n",
       " ['oh', 'dear', '!'],\n",
       " ['i', 'shall', 'be', 'late', '!', \"'\"],\n",
       " ['(',\n",
       "  'when',\n",
       "  'she',\n",
       "  'thought',\n",
       "  'it',\n",
       "  'over',\n",
       "  'afterwards',\n",
       "  ',',\n",
       "  'it',\n",
       "  'occurred',\n",
       "  'to',\n",
       "  'her',\n",
       "  'that',\n",
       "  'she',\n",
       "  'ought',\n",
       "  'to',\n",
       "  'have',\n",
       "  'wondered',\n",
       "  'at',\n",
       "  'this',\n",
       "  ',',\n",
       "  'but',\n",
       "  'at',\n",
       "  'the',\n",
       "  'time',\n",
       "  'it',\n",
       "  'all',\n",
       "  'seemed',\n",
       "  'quite',\n",
       "  'natural',\n",
       "  ')',\n",
       "  ';',\n",
       "  'but',\n",
       "  'when',\n",
       "  'the',\n",
       "  'rabbit',\n",
       "  'actually',\n",
       "  'took',\n",
       "  'a',\n",
       "  'watch',\n",
       "  'out',\n",
       "  'of',\n",
       "  'its',\n",
       "  'waistcoat-pocket',\n",
       "  ',',\n",
       "  'and',\n",
       "  'looked',\n",
       "  'at',\n",
       "  'it',\n",
       "  ',',\n",
       "  'and',\n",
       "  'then',\n",
       "  'hurried',\n",
       "  'on',\n",
       "  ',',\n",
       "  'alice',\n",
       "  'started',\n",
       "  'to',\n",
       "  'her',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'for',\n",
       "  'it',\n",
       "  'flashed',\n",
       "  'across',\n",
       "  'her',\n",
       "  'mind',\n",
       "  'that',\n",
       "  'she',\n",
       "  'had',\n",
       "  'never',\n",
       "  'before',\n",
       "  'seen',\n",
       "  'a',\n",
       "  'rabbit',\n",
       "  'with',\n",
       "  'either',\n",
       "  'a',\n",
       "  'waistcoat-pocket',\n",
       "  ',',\n",
       "  'or',\n",
       "  'a',\n",
       "  'watch',\n",
       "  'to',\n",
       "  'take',\n",
       "  'out',\n",
       "  'of',\n",
       "  'it',\n",
       "  ',',\n",
       "  'and',\n",
       "  'burning',\n",
       "  'with',\n",
       "  'curiosity',\n",
       "  ',',\n",
       "  'she',\n",
       "  'ran',\n",
       "  'across',\n",
       "  'the',\n",
       "  'field',\n",
       "  'after',\n",
       "  'it',\n",
       "  ',',\n",
       "  'and',\n",
       "  'fortunately',\n",
       "  'was',\n",
       "  'just',\n",
       "  'in',\n",
       "  'time',\n",
       "  'to',\n",
       "  'see',\n",
       "  'it',\n",
       "  'pop',\n",
       "  'down',\n",
       "  'a',\n",
       "  'large',\n",
       "  'rabbit-hole',\n",
       "  'under',\n",
       "  'the',\n",
       "  'hedge',\n",
       "  '.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "# iterate through each sentence in the file \n",
    "for i in sent_tokenize(f): \n",
    "    temp = [] \n",
    "      \n",
    "    # tokenize the sentence into words \n",
    "    for j in word_tokenize(i): \n",
    "        temp.append(j.lower()) \n",
    "  \n",
    "    data.append(temp)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CBOW model \n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1,size = 100, window = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'alice' and 'wonderland' - CBOW :  0.050018195\n"
     ]
    }
   ],
   "source": [
    "# Print results \n",
    "print(\"Cosine similarity between 'alice' \" + \n",
    "               \"and 'wonderland' - CBOW : \", \n",
    "    model1.similarity('alice', 'was')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'alice' and 'machines' - CBOW :  -0.055909645\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'alice' \" +\n",
    "                 \"and 'machines' - CBOW : \", \n",
    "      model1.similarity('alice', 'and')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Skip Gram model \n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, \n",
    "                                             window = 5, sg = 1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'alice' and 'wonderland' - Skip Gram :  0.99999994\n",
      "Cosine similarity between 'alice' and 'machines' - Skip Gram :  0.99999994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print results \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "          \"and 'wonderland' - Skip Gram : \", \n",
    "    model2.similarity('alice', 'alice')) \n",
    "      \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "            \"and 'machines' - Skip Gram : \", \n",
    "      model2.similarity('alice', 'alice')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
